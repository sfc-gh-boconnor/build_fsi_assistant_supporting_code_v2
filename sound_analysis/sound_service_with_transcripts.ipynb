{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463050b4-bef4-4c6b-bedf-d1851064869b",
   "metadata": {
    "collapsed": false,
    "name": "heading_create_service",
    "resultHeight": 183
   },
   "source": [
    "# Create a Service to transcrbe the earnings call\n",
    "The whisper service has already transcribed sound files relating to the earnings calls.  It was hosted on a snowpark container and it processed each file with a medium sized GPU.  Whisper leverages pytorch (a deap leaning framework) to parse and transcribe the text.\n",
    "\n",
    "***COMING SOON*** - Soon, a new multi modal **Transcribe** cortex function will be available.  This will mean that one simple function will allow you to transcribe sound from a file **WITHOUT ANY SETUP**.\n",
    "\n",
    "For today, we will use the transcripts which were processed in advance of this lab.  For reference, the results are shared to you via the **Internal Marketplace**\n",
    "\n",
    "***FOR INFORMATION***\n",
    "\n",
    "**Snowflake Data Foundations** is a product on the marketplace which include event transcripts.  There is a 30 day trial available.\n",
    "\n",
    "Click [here](https://app.snowflake.com/marketplace/listing/GZTSZ290BUX66/snowflake-data-snowflake-data-foundations?search=foundations) to find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43f053-4480-4ab8-b503-d8d15e23d9fa",
   "metadata": {
    "collapsed": false,
    "name": "run_functions",
    "resultHeight": 47
   },
   "source": [
    "####  Listen to the calls that were transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eeffd1-5a10-46fd-be4c-83d1b2078656",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "view_each_call",
    "resultHeight": 161
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "files = session.sql('''SELECT RELATIVE_PATH, GET_PRESIGNED_URL('@DOCUMENT_AI.EARNINGS_CALLS',RELATIVE_PATH) URL FROM DIRECTORY (@DOCUMENT_AI.EARNINGS_CALLS)''')\n",
    "\n",
    "\n",
    "select_call = st.selectbox('Select Call:', files.select('RELATIVE_PATH'))\n",
    "\n",
    "URL = files.filter(col('RELATIVE_PATH') == select_call).select('URL').collect()[0][0]\n",
    "st.audio(URL, format=\"audio/mpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d5b19-ed63-4ead-9622-bc26a0967692",
   "metadata": {
    "collapsed": false,
    "name": "heading_table_transcript",
    "resultHeight": 47
   },
   "source": [
    "#### The sound files have already been transcribed using the whisper service.\n",
    "We will now create a table based on the raw results produced by the Whisper Service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54974b-086e-4d3b-a58d-70fa30081dc6",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "table_transcript",
    "resultHeight": 182
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DEFAULT_SCHEMA.EARNINGS_CALL_TRANSCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c082740-2faf-4885-aab9-bb9ed19f3bcf",
   "metadata": {
    "collapsed": false,
    "name": "heading_view_transcript",
    "resultHeight": 46
   },
   "source": [
    "### Transform the transcript table\n",
    "We are creating a table which is flattening the generated whisper data.  This creates a row for every snippet of commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893c881-d45a-4388-9dda-bdfce79a65ed",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_table_formatted_transcripts_with_sentiments",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS AS\n",
    "\n",
    "SELECT RELATIVE_PATH, PARSE_JSON(TRANSCRIPT):language::TEXT LANGUAGE,\n",
    "\n",
    "VALUE:end::FLOAT TIME_SECONDS,  \n",
    "VALUE:text::TEXT TEXT \n",
    "FROM DEFAULT_SCHEMA.EARNINGS_CALL_TRANSCRIPT,\n",
    "LATERAL FLATTEN (PARSE_JSON(TRANSCRIPT):segments);\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098216c2-20b6-4935-b0d3-815986f9e664",
   "metadata": {
    "collapsed": false,
    "name": "heading_add_sentiment",
    "resultHeight": 47
   },
   "source": [
    "#### Add Sentiment scores to the calls\n",
    "Here, Cortex Sentiment is being used to generate a sentiment score for each text snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65821c72-41ad-4d5a-ab8a-fb9f290f24ec",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "with_sentiment",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "SELECT *, SNOWFLAKE.CORTEX.SENTIMENT(TEXT) FROM DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337bffc-9f87-4c3d-8739-6676a4b12549",
   "metadata": {
    "collapsed": false,
    "name": "heading_Streamlit",
    "resultHeight": 47
   },
   "source": [
    "#### Put all together in Streamlit\n",
    "Let's now have a look at the results using a visualistion in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6068f0-ea09-47f0-b4c9-438ace28179c",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "earnings_sentiment",
    "resultHeight": 977
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "def sentiment(text):\n",
    "    return call_function('snowflake.cortex.sentiment',text)\n",
    "\n",
    "transcript_with_sentiment = session.table('DEFAULT_SCHEMA.TRANSCRIBED_TRANSCRIPTS').with_column('sentiment',sentiment(col('TEXT')))\n",
    "\n",
    "st.markdown('#### Calls with Sentiment')\n",
    "\n",
    "\n",
    "st.dataframe(transcript_with_sentiment)\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='TIME_SECONDS',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3428-ea67-40ca-a1b0-9263ea9a5d02",
   "metadata": {
    "collapsed": false,
    "name": "hard_to_read"
   },
   "source": [
    "You will see that the line charts are very hard to read.  Also with such a small snippet of information, it is difficult to get a good sentiment score.  Unlike the chunking which you did with the Analyst reports, this time we are going to group snippets of data together for every 60 seconds and then create an average sentiment for each minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d30301-7651-48e9-b3b6-9d1f9b480323",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "sentiment_minutes",
    "resultHeight": 464
   },
   "outputs": [],
   "source": [
    "grouped = transcript_with_sentiment.with_column('TIME',time_from_parts(15,0,'TIME_SECONDS')).\\\n",
    "with_column('MINUTES',date_trunc('minute','TIME'))\n",
    "grouped = grouped.with_column('MINUTES',minute('MINUTES'))\n",
    "data_grouped_minutes = grouped.group_by('RELATIVE_PATH','MINUTES').agg(array_agg('TEXT').alias('TEXT'),avg('SENTIMENT').alias('SENTIMENT'))\n",
    "\n",
    "st.markdown('''#### Data Grouped to Minutes''')\n",
    "data_grouped_minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df2b58-e1be-4ffd-94ed-30642dd1d85d",
   "metadata": {
    "collapsed": false,
    "name": "smoother"
   },
   "source": [
    "Below is a much smoother output - and a lot easier to read.  We are also able to view these grouped snippets in the visualistion.  Here, we are featuring the Most popular minute of the year, followed by the most negative minute of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb79850-3258-44dc-8552-ae0c126dd812",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "grouped_minutes",
    "resultHeight": 790
   },
   "outputs": [],
   "source": [
    "st.markdown('#### Sentiment Analysis during the duration of the last 3 quarterly earnings calls')\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "st.markdown(f'''**:bulb: Most positive minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').desc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')\n",
    "\n",
    "st.markdown(f'''**:warning: Most negative minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').asc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3e259-c75e-41a0-9577-513a6a5af6a5",
   "metadata": {
    "collapsed": false,
    "name": "regexp"
   },
   "source": [
    "Now lets remove the arrays to visualise pure text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46c13e-7e46-46a9-b4ea-1a8f83294f61",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "format_text",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "grouped_text = data_grouped_minutes.with_column(\n",
    "    'TEXT',\n",
    "    regexp_replace(cast(col('TEXT'), StringType()), r'[\\[\\]\"]', '')).sort(col('RELATIVE_PATH'),col('MINUTES')\n",
    ")\n",
    "grouped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2ba53-bbba-463d-84b7-aafea838a2f1",
   "metadata": {
    "collapsed": false,
    "name": "focus_entire_call"
   },
   "source": [
    "We will now put all the minutes of the call together so we can see a complete picture of each call. We also summarise the call and put a final sentiment score for the entire call.  Have a look at the sentiment call when the entire call is put in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84fa76-7177-46f3-9ca5-9013734a06bd",
   "metadata": {
    "language": "python",
    "name": "aggregate_text_per_call"
   },
   "outputs": [],
   "source": [
    "entire_call = grouped_text.group_by('RELATIVE_PATH').agg(array_agg('TEXT').alias('TEXT')).with_column('TEXT',array_to_string('TEXT',lit(' ')))\n",
    "\n",
    "entire_call = entire_call.with_column('SUMMARY',snowflake_cortex_summarize(col('TEXT')))\n",
    "entire_call = entire_call.with_column('SENTIMENT',call_function('SNOWFLAKE.CORTEX.SENTIMENT',(col('TEXT'))))\n",
    "entire_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f000610-a836-4b17-aa9e-c192b48379dc",
   "metadata": {
    "collapsed": false,
    "name": "heading_save_data_in_table",
    "resultHeight": 47
   },
   "source": [
    "#### Save data in a table\n",
    "Finally lets save the results in a table.   Let's examine the text further with text based search functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20573f93-500d-48d8-b4bd-aa7bf3334dbf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_table",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "grouped_text.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.transcripts_by_minute\")\n",
    "entire_call.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.full_transcripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849dee4e-9d0e-46f0-b747-65330c11f782",
   "metadata": {
    "collapsed": false,
    "name": "head_embeddings"
   },
   "source": [
    "### VECTOR EMBEDDINGS\n",
    "The calls will be chunked and then embedded to make them searchable.\n",
    "\n",
    "An embedding refers to the reduction of high-dimensional data, such as unstructured text, to a representation with fewer dimensions, such as a vector. Modern deep learning techniques can create vector embeddings, which are structured numerical representations, from unstructured data such as text and images, preserving semantic notions of similarity and dissimilarity in the geometry of the vectors they produce.\n",
    "\n",
    "The illustration below is a simplified example of the vector embedding and geometric similarity of natural language text. In practice, neural networks produce embedding vectors with hundreds or even thousands of dimensions, not two as shown here, but the concept is the same. Semantically similar text yields vectors that “point” in the same general direction.\n",
    "\n",
    "![embeddings](https://docs.snowflake.com/en/_images/vector-similarity-vectors-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba5efd-74a0-4c85-9e0c-6b35cf1ce205",
   "metadata": {
    "collapsed": false,
    "name": "head_split_embed"
   },
   "source": [
    "Below uses cortex **split text recursive character** to split as before, and in addition, uses **embed text 1024** to embed the text to 1024 dimensions.\n",
    "\n",
    "As the data is chunked based on number of characters with the addition to an overlap, a new sentiment score is also added to the new chunked table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef656f67-a497-461e-a2a1-054ba09d97e4",
   "metadata": {
    "language": "python",
    "name": "embed_text"
   },
   "outputs": [],
   "source": [
    "entire_call = session.table('DEFAULT_SCHEMA.full_transcripts')\n",
    "#### chunk the calls ####\n",
    "chunked = entire_call.with_column('TEXT',call_function('SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER',col('TEXT'),'none',500,20))\n",
    "chunked = chunked.join_table_function('flatten','TEXT').select('RELATIVE_PATH','SUMMARY',col('VALUE').astype(StringType()).alias('TEXT'))\n",
    "\n",
    "#### apply sentiment per chunk\n",
    "\n",
    "chunked = chunked.with_column('SENTIMENT',call_function('SNOWFLAKE.CORTEX.SENTIMENT',col('TEXT')))\n",
    "#### embed the calls ###\n",
    "\n",
    "chunked = chunked.with_column('EMBED',call_function('SNOWFLAKE.CORTEX.EMBED_TEXT_1024',lit('snowflake-arctic-embed-l-v2.0'),col('TEXT')))\n",
    "\n",
    "\n",
    "chunked.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.call_embeds\")\n",
    "chunked = session.table('DEFAULT_SCHEMA.call_embeds')\n",
    "chunked.limit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e66aca-74d1-4836-b343-f2aa3a537fdb",
   "metadata": {
    "collapsed": false,
    "name": "head_search"
   },
   "source": [
    "Now you will try and search the call text using the the search box below.  It will compare the embedded search **phrase** with the embeddings of the chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104325a-9a70-40a4-aee3-8da9fd48fbf9",
   "metadata": {
    "language": "python",
    "name": "embeds_and_search"
   },
   "outputs": [],
   "source": [
    "call = st.selectbox('Select Call:',entire_call.select('RELATIVE_PATH').distinct())\n",
    "\n",
    "with st.container(height=900):\n",
    "    st.markdown('### SUMMARY')\n",
    "    chunked.filter(col('RELATIVE_PATH')==call).select('SUMMARY').collect()[0][0]\n",
    "    keyword = st.text_input('Search Text:')\n",
    "    search = chunked.filter(col('RELATIVE_PATH')==call)\n",
    "    \n",
    "    search = search.with_column('embed_search',call_function('SNOWFLAKE.CORTEX.EMBED_TEXT_1024',\n",
    "                                                     lit('snowflake-arctic-embed-l-v2.0'),\n",
    "                                                     lit(keyword)).alias('TOKEN'))\n",
    "\n",
    "    search = search.with_column('score',call_function('VECTOR_COSINE_SIMILARITY',col('EMBED'),col('EMBED_SEARCH')))\n",
    "    st.markdown('### SEARCH RESULTS')\n",
    "    st.table(search.select('TEXT','SCORE','SENTIMENT').sort(col('score').desc()).limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0edda-d196-4879-bedf-ee86b5066ed1",
   "metadata": {
    "collapsed": false,
    "name": "search_service"
   },
   "source": [
    "This is the principle of how the search service works.  Cortex search does all the embeddings for the user, this is what you will do in the next section - **Create a Search Service**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "5503774339929",
   "authorName": "USER",
   "lastEditTime": 1746009788030,
   "notebookId": "q5unj46flrwbsgt25ngd",
   "sessionId": "33efeb90-3e58-49cf-bfa7-1b8786a360f6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
